# -*- coding: utf-8 -*-
"""Dicoding | ML Terapan | DiabetesRiskPrediction

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1UzdPNnHdJr94qArUk0s9hH6tEBtlBoQH

# Prepared for Data
"""

!mkdir -p ~/.kaggle
!cp kaggle.json ~/.kaggle/
!chmod 600 ~/.kaggle/kaggle.json

# Instal library Kaggle
!pip install kaggle

# Unduh dataset dari Kaggle
!kaggle datasets download -d tanshihjen/early-stage-diabetes-risk-prediction

# Ekstrak file zip yang diunduh
!unzip early-stage-diabetes-risk-prediction.zip

"""# Predictive Modeling for Diabetes Risk Assessment: Exploring Feature Associations and Evaluating Classification Algorithms

# Data Loading & Understanding
"""

# Commented out IPython magic to ensure Python compatibility.
# import essential libraries
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

# %matplotlib inline

data = pd.read_csv('diabetes_risk_prediction_dataset.csv')

print('Dimension of the dataset: ', data.shape)

print('Attributes in the dataset: ', data.columns.values)
data.head()

data.describe()

"""#### Attributes Description:

- Age (1-20 to 65): Age range of the individuals.
- Sex (1. Male, 2. Female): Gender information.
- Polyuria (1. Yes, 2. No): Presence of excessive urination.
- Polydipsia (1. Yes, 2. No): Excessive thirst.
- sudden weight loss (1. Yes, 2. No): Abrupt weight loss.
- weakness (1. Yes, 2. No): Generalized weakness.
- Polyphagia (1. Yes, 2. No): Excessive hunger.
- Genital Thrush (1. Yes, 2. No): Presence of genital thrush.
- visual blurring (1. Yes, 2. No): Blurring of vision.
- Itching (1. Yes, 2. No): Presence of itching.
- Irritability (1. Yes, 2. No): Display of irritability.
- delayed healing (1. Yes, 2. No): Delayed wound healing.
- partial paresis (1. Yes, 2. No): Partial loss of voluntary movement.
- muscle stiffness (1. Yes, 2. No): Presence of muscle stiffness.
- Alopecia (1. Yes, 2. No): Hair loss.
- Obesity (1. Yes, 2. No): Presence of obesity.
- class (1. Positive, 2. Negative): Diabetes classification.
"""

data.info()

"""# Exploratory Data Analysis (EDA)"""

# Distribusi variabel target
sns.countplot(x='class', data=data)
plt.title('Distribution of Outcome')
plt.show()

# Pairplot untuk hubungan pasangan variabel
sns.pairplot(data, hue='class', diag_kind='kde')
plt.show()

# Box plot untuk analisis fitur
sns.boxplot(x='class', y='Age', data=data)
plt.title('Boxplot of Age by Class')
plt.show()

sns.boxplot(x='class', y='Gender', data=data)
plt.title('Boxplot of Gender by Class')
plt.show()

# Histogram untuk distribusi fitur
data.hist(bins=30, figsize=(20, 15), color='blue')
plt.show()

# Count plot untuk fitur kategorikal
sns.countplot(x='Gender', data=data, palette='Set2')
plt.title('Countplot of Gender')
plt.show()

sns.countplot(x='Polyuria', data=data, palette='Set2')
plt.title('Countplot of Polyuria')
plt.show()

# Box plot untuk analisis fitur
plt.figure(figsize=(12, 6))

# Polyuria
sns.boxplot(x='class', y='Age', hue='Polyuria', data=data)
plt.title('Boxplot of Age by Class and Polyuria')
plt.show()

# Polydipsia
sns.boxplot(x='class', y='Age', hue='Polydipsia', data=data)
plt.title('Boxplot of Age by Class and Polydipsia')
plt.show()

# Obesity
sns.boxplot(x='class', y='Age', hue='Obesity', data=data)
plt.title('Boxplot of Age by Class and Obesity')
plt.show()

# distribution of diabetic and non-diabetic samples
samples = data['class'].value_counts()
colors = ['midnightblue','silver']

figure, axes = plt.subplots(1,2, figsize=(15,5), gridspec_kw={'width_ratios':[1.5,1]})
axes[0].barh(y=samples.index, width=samples.values, color=colors)
axes[0].set_xlabel('Frequency')
axes[0].set_yticks(['Negative','Positive'],['Non-diabetic','Diabetic'])
axes[0].grid(alpha=0.4)

for index, values in enumerate(samples):
    axes[0].text(values+3, index, str(values), va='center')

axes[1].pie(samples.values, labels=['Diabetic','Non-diabetic'], autopct='%.2f%%', explode=([0.05]*len(samples.index)), colors=colors)
figure.suptitle('Diabetic vs Non-Diabetic', fontsize=15)
plt.tight_layout(pad=1)
plt.show()

from scipy.stats import chi2_contingency

def chi2test(feature):
    # visualization
    plt.figure(figsize=(12,5))
    ax = sns.countplot(data=data, x=data[feature], hue=data['class'], palette=colors)
    ax.legend(['Diabetic','Non-diabetic'], loc='upper right', bbox_to_anchor=(1.2, 1))
    plt.title(f'Diabetic vs Non-Diabetic by {feature}', fontsize=15)
    plt.grid(alpha=0.4)
    plt.show()

    # display the contingency table (observed value)
    contingency_table = pd.crosstab(data[feature],data['class'])
    contingency_table.columns = ['Diabetic','Non-diabetic']
    print('Observed value:')
    display(contingency_table)

    # perform Chi-square test
    res = chi2_contingency(contingency_table)
    test_stat = round(res[0], 4)
    pvalue = round(res[1], 4)
    expected_frequency = res[3]

    print('Expected frequency:')
    display(pd.DataFrame(expected_frequency, index=contingency_table.index, columns=contingency_table.columns))

    print('Test statistics: ', test_stat)
    print('Test p-value: ', pvalue)

    alpha = 0.05
    if pvalue < alpha:
        print(f'Reject null hypothesis. There is a statistically significant association between {feature} and the likelihood of diabetes in the analyzed data.')
    else:
        print(f'Failed to reject null hypothesis. Lack of evidence to conclude a statistically significant association between {feature} and the likelihood of diabetes in the analyzed data.')

"""#### Question 1 | Is there a statistically significant association between gender and the likelihood of diabetes?"""

chi2test('Gender')

"""#### Question 2 | Does the presence of polyuria exhibit a statistically significant association with the likelihood of diabetes?"""

chi2test('Polyuria')

"""#### Question 3 | Does the presence of polydipsia exhibit a statistically significant association with the likelihood of diabetes?"""

chi2test('Polydipsia')

"""#### Question 4 | Is there a statistically significant association between the presence of sudden weight loss and the likelihood of diabetes?"""

chi2test('sudden weight loss')

"""#### Question 5 | Does the presence of weakness exhibit a statistically significant association with the likelihood of diabetes?"""

chi2test('weakness')

"""#### Question 6 | Is there a statistically significant association between the presence of polyphagia and the likelihood of diabetes?"""

chi2test('Polyphagia')

"""#### Question 7 | Is there a statistically significant association between the presence of genital thrush and the likelihood of diabetes?"""

chi2test('Genital thrush')

"""#### Question 8 | Is there a statistically significant association between the presence of visual blurring and the likelihood of diabetes?"""

chi2test('visual blurring')

"""#### Question 9 | Is there a statistically significant association between the presence of irritability and the likelihood of diabetes?"""

chi2test('Irritability')

"""#### Question 10 | Does the presence of delayed healing exhibit a statistically significant association with the likelihood of diabetes?"""

chi2test('delayed healing')

"""#### Question 11 | Does the presence of partial paresis exhibit a statistically significant association with the likelihood of diabetes?"""

chi2test('partial paresis')

"""#### Question 12 | Does the presence of muscle stiffness exhibit a statistically significant association with the likelihood of diabetes?"""

chi2test('muscle stiffness')

"""#### Question 13 | Does the presence of alopecia exhibit a statistically significant association with the likelihood of diabetes?"""

chi2test('Alopecia')

"""#### Question 14 | Does obesity exhibit a statistically significant association with the likelihood of diabetes?"""

chi2test('Obesity')

"""# Predictive Analytics
#### Data Preprocessing for Modelling
"""

from sklearn.model_selection import train_test_split

train, test = train_test_split(data, test_size=0.2, random_state=122)

# dimension of train and test dataset
print('Dimension of training data: ', train.shape)
print('Dimension of test data: ', test.shape)

# segregate the feature matrix and target vector from train and test data
Xtrain = train.drop(columns=['class'], axis=1)
ytrain = train['class']

Xtest = test.drop(columns=['class'], axis=1)
ytest = test['class']

# encode the target/label for train and test dataset
from sklearn.preprocessing import LabelEncoder

encoder = LabelEncoder()
ytrain_encoded = encoder.fit_transform(ytrain)
ytest_encoded = encoder.transform(ytest)

from sklearn.compose import ColumnTransformer
from sklearn.pipeline import Pipeline
from sklearn.preprocessing import OneHotEncoder, MinMaxScaler

#  using OneHotEncoder
excluded_col = 'Age'
categorical_col = [col for col in Xtrain.columns if col != excluded_col]

preprocessor = ColumnTransformer(
    transformers=[
        ('cat', OneHotEncoder(drop='first'), categorical_col)
    ],
    remainder='passthrough'
)

# create the pipeline
pipeline = Pipeline([
    ('preprocessor', preprocessor),
    ('scaler', MinMaxScaler())
])

# process the train and test data
Xtrain_transformed = pipeline.fit_transform(Xtrain)
Xtest_transformed = pipeline.transform(Xtest)

"""# Classification
#### Model 1 | Decision Tree
"""

from sklearn.tree import DecisionTreeClassifier
from sklearn.model_selection import GridSearchCV

# create a Decision Tree Classifier
tree = DecisionTreeClassifier(random_state=122)

# Define the hyperparameter grid
param_grid = {
    'criterion': ['gini', 'entropy'],
    'splitter': ['best', 'random'],
    'max_depth': [10, 20, 30],
    'min_samples_split': [2, 5, 10],
    'min_samples_leaf': [2, 4]
}

# create the GridSearchCV object
grid_search_tree = GridSearchCV(tree, param_grid, cv=5, scoring='accuracy', n_jobs=-1)

# fit the grid search to the data
grid_search_tree.fit(Xtrain_transformed, ytrain_encoded)

# print the best parameters and the corresponding accuracy
print('Best Parameters: ', grid_search_tree.best_params_)
print('Best Accuracy: ', grid_search_tree.best_score_)

# get the best model
best_tree = grid_search_tree.best_estimator_

"""#### Model 2 | Logistic Regression"""

from sklearn.linear_model import LogisticRegression

# create a logistic regression Classifier
logreg = LogisticRegression(random_state=122, max_iter=5000)

# define the hyperparameter grid
param_grid = {
    'penalty': ['l1', 'l2'],
    'C': [0.001, 0.01, 0.1, 1, 10, 100],
    'solver': ['liblinear', 'saga']
}

# create the GridSearchCV object
grid_search_logreg = GridSearchCV(logreg, param_grid, cv=5, scoring='accuracy', n_jobs=-1)

# fit the grid search to the data
grid_search_logreg.fit(Xtrain_transformed, ytrain_encoded)

# print the best parameters and the corresponding accuracy
print('Best Parameters: ', grid_search_logreg.best_params_)
print('Best Accuracy: ', grid_search_logreg.best_score_)

# get the best model
best_logreg = grid_search_logreg.best_estimator_

"""#### Model 3 | Random Forest"""

from sklearn.ensemble import RandomForestClassifier

# create a Random Forest Classifier
forest = RandomForestClassifier(random_state=122)

# define the hyperparameter grid
param_grid = {
    'n_estimators': [100, 200, 300],
    'criterion': ['gini', 'entropy'],
    'max_depth': [10, 20, 30],
    'min_samples_split': [2, 5, 10],
    'min_samples_leaf': [2, 4],
    'max_features': ['sqrt', 'log2']
}

# create the GridSearchCV object
grid_search_forest = GridSearchCV(forest, param_grid, cv=5, scoring='accuracy', n_jobs=-1)

# fit the grid search to the data
grid_search_forest.fit(Xtrain_transformed, ytrain_encoded)

# print the best parameters and the corresponding accuracy
print('Best Parameters: ', grid_search_forest.best_params_)
print('Best Accuracy: ', grid_search_forest.best_score_)

# get the best model
best_forest = grid_search_forest.best_estimator_

"""#### Model 4 | Naive Bayes"""

from sklearn.naive_bayes import ComplementNB

# create a Naive Bayes classifier
clf = ComplementNB()

# fit the classifier with training data
cNB = clf.fit(Xtrain_transformed,ytrain_encoded)

"""#### Model 5 | KNearestNeighbors"""

from sklearn.neighbors import KNeighborsClassifier

# create the KNN classifier
knn = KNeighborsClassifier()

# define the parameter grid for hyperparameter tuning
param_grid = {
    'n_neighbors': np.arange(1, 21),
    'p': [1, 2]  # 1 for Manhattan distance (L1), 2 for Euclidean distance (L2)
}

# create a GridSearchCV object with KNN and the parameter grid
grid_search_knn = GridSearchCV(knn, param_grid, cv=5, scoring='accuracy', n_jobs=-1)

# fit the model with the training data
grid_search_knn.fit(Xtrain_transformed,ytrain_encoded)

# print the best parameters and the corresponding accuracy
print('Best Parameters: ', grid_search_knn.best_params_)
print('Best Accuracy: ', grid_search_knn.best_score_)

# get the best model
best_knn = grid_search_knn.best_estimator_

"""#### Model 6 | Support Vector Machine (SVM)"""

from sklearn.svm import SVC

# create the SVM classifier
svc = SVC(random_state=122)

# define the parameter grid for hyperparameter tuning
param_grid = {
    'C': [0.1, 1, 10, 100],                 # Regularization parameter
    'kernel': ['linear', 'rbf', 'poly'],    # Choice of kernel
    'gamma': ['scale', 'auto', 0.1, 1],     # Kernel coefficient for 'rbf' and 'poly'
    'degree': [2, 3, 4]                     # Degree of the polynomial kernel
}

# create a GridSearchCV object with SVM and the parameter grid
grid_search_svc = GridSearchCV(svc, param_grid, cv=5, scoring='accuracy')

# fit the model with the training data
grid_search_svc.fit(Xtrain_transformed,ytrain_encoded)

# print the best parameters and the corresponding accuracy
print('Best Parameters: ', grid_search_svc.best_params_)
print('Best Accuracy: ', grid_search_svc.best_score_)

# get the best model
best_svc = grid_search_svc.best_estimator_

"""# Performance Evaluation & Model Comparison"""

# define a helper function to perform model evaluation based on key metrics
from sklearn.metrics import precision_recall_fscore_support, matthews_corrcoef

def performance_evaluation(X,y,clf,classifier_name=''):
    ypred = clf.predict(X)
    accuracy = clf.score(X,y)
    mcc = matthews_corrcoef(y, ypred)
    precision, recall, fscore, support = precision_recall_fscore_support(y, ypred, average='weighted', zero_division=0)
    metricName = ['Accuracy','Precision','Recall','F1_Score','MCC']
    metricValue = [accuracy,precision,recall,fscore,mcc]
    res = pd.DataFrame(metricValue, index=metricName, columns=[classifier_name])
    return res

# generate the performance summary for various models trained
tree_summary = performance_evaluation(Xtest_transformed,ytest_encoded,best_tree,'Decision Tree')
logistic_summary = performance_evaluation(Xtest_transformed,ytest_encoded,best_logreg,'Logistic Regression')
forest_summary = performance_evaluation(Xtest_transformed,ytest_encoded,best_forest,'Random Forest')
naivebayes_summary = performance_evaluation(Xtest_transformed,ytest_encoded,cNB,'Naive Bayes')
knn_summary = performance_evaluation(Xtest_transformed,ytest_encoded,best_knn,'K Nearest Neigbors')
svc_summary = performance_evaluation(Xtest_transformed,ytest_encoded,best_svc,'Support Vector Machine')

# combine the summary of each model into a dataframe
comparison_df = pd.concat([tree_summary,forest_summary,logistic_summary,naivebayes_summary,knn_summary,svc_summary], axis=1)

# disply the summary dafaframe
display(comparison_df)

"""##### Notes:

The Matthews Correlation Coefficient (MCC) is a metric commonly used to assess the performance of binary classification models. It takes into account true positives, true negatives, false positives, and false negatives and provides a balanced measure, especially when the classes are imbalanced.


Here's why MCC is a useful metric:

1. **Balancing Act:** MCC takes into account all four elements of the confusion matrix, making it suitable for imbalanced datasets. This is crucial when the number of instances in one class is much higher than the other, as accuracy alone can be misleading.

2. **Range of Values:** MCC ranges from -1 to 1. A score of 1 indicates a perfect prediction, 0 means no better than random, and -1 indicates total disagreement between prediction and observation. This range provides a clear understanding of the quality of the model.

3. **Symmetry:** MCC is symmetric; it considers errors in both positive and negative classes. This is especially important when the costs of false positives and false negatives are different.

4. **Effectiveness in Binary Classification:** MCC is particularly effective for binary classification problems and is less sensitive to class imbalance compared to some other metrics like accuracy.
"""

# visualize the confusion matrix using a heatmap
from sklearn.metrics import confusion_matrix
import seaborn as sns
import matplotlib.pyplot as plt

labels = ['Diabetic', 'Non-diabetic']

ypred_tree = best_tree.predict(Xtest_transformed)
cm_tree = confusion_matrix(ytest_encoded, ypred_tree, normalize='true')

ypred_forest = best_forest.predict(Xtest_transformed)
cm_forest = confusion_matrix(ytest_encoded, ypred_forest, normalize='true')

ypred_logistic = best_logreg.predict(Xtest_transformed)
cm_logistic = confusion_matrix(ytest_encoded, ypred_logistic, normalize='true')

ypred_nb = cNB.predict(Xtest_transformed)
cm_nb = confusion_matrix(ytest_encoded, ypred_nb, normalize='true')

ypred_knn = best_knn.predict(Xtest_transformed)
cm_knn = confusion_matrix(ytest_encoded, ypred_knn, normalize='true')

ypred_svc = best_svc.predict(Xtest_transformed)
cm_svc = confusion_matrix(ytest_encoded, ypred_svc, normalize='true')

# confusion matrix for 6 classification models
figure, axes = plt.subplots(3, 2, figsize=(12, 12))

# Plot for Decision Tree
sns.heatmap(cm_tree, annot=True, cmap='YlGnBu', xticklabels=labels, yticklabels=labels, cbar=False, ax=axes[0, 0])
axes[0, 0].set_title('Decision Tree', fontsize=20)

# Plot for Random Forest
sns.heatmap(cm_forest, annot=True, cmap='YlGnBu', xticklabels=labels, yticklabels=labels, cbar=False, ax=axes[0, 1])
axes[0, 1].set_title('Random Forest', fontsize=20)

# Plot for Logistic Regression
sns.heatmap(cm_logistic, annot=True, cmap='YlGnBu', xticklabels=labels, yticklabels=labels, cbar=False, ax=axes[1, 0])
axes[1, 0].set_title('Logistic Regression', fontsize=20)

# Plot for Naive Bayes
sns.heatmap(cm_nb, annot=True, cmap='YlGnBu', xticklabels=labels, yticklabels=labels, cbar=False, ax=axes[1, 1])
axes[1, 1].set_title('Naive Bayes', fontsize=20)

# Plot for K Nearest Neighbors
sns.heatmap(cm_knn, annot=True, cmap='YlGnBu', xticklabels=labels, yticklabels=labels, cbar=False, ax=axes[2, 0])
axes[2, 0].set_title('K Nearest Neighbors', fontsize=20)

# Plot for Support Vector Machine (SVM)
sns.heatmap(cm_svc, annot=True, cmap='YlGnBu', xticklabels=labels, yticklabels=labels, cbar=False, ax=axes[2, 1])
axes[2, 1].set_title('Support Vector Machine (SVM)', fontsize=20)

# Adjust the layout and title
figure.suptitle('Confusion Matrix of 6 Classification Models', fontsize=15)
plt.tight_layout(pad=1)
plt.show()

"""# Conclusion

In my analysis, I identified several key factors significantly associated with the likelihood of diabetes, including Gender, Polyuria, Polydipsia, sudden weight loss, weakness, Polyphagia, Genital thrush, visual blurring, Irritability, partial paresis, muscle stiffness, and Alopecia. Conversely, Itching and delayed healing did not show significant associations. Age also emerged as an important predictive factor, with a notable difference between diabetic and non-diabetic individuals.

I then utilized multiple classification models to predict diabetes risk. The K Nearest Neighbors model emerged as the most accurate and precise, achieving an accuracy of 96.15% and precision of 96.19%. Decision Tree and Random Forest models also showed strong performance, with accuracies and precisions around 94%. Support Vector Machine demonstrated robust metrics across the board. While Logistic Regression and Naive Bayes achieved reasonable accuracy, their precision and MCC scores were comparatively lower.

Overall, the K Nearest Neighbors, Decision Tree, and Random Forest models are well-suited for predicting diabetes risk based on my dataset, with K Nearest Neighbors being the most effective.
"""